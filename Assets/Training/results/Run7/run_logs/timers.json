{
    "name": "root",
    "gauges": {
        "PlaneMovement.Policy.Entropy.mean": {
            "value": 3.0977582931518555,
            "min": 1.219660758972168,
            "max": 3.1803040504455566,
            "count": 20
        },
        "PlaneMovement.Policy.Entropy.sum": {
            "value": 156164.1875,
            "min": 61939.25390625,
            "max": 158080.8125,
            "count": 20
        },
        "PlaneMovement.Step.mean": {
            "value": 999876.0,
            "min": 49969.0,
            "max": 999876.0,
            "count": 20
        },
        "PlaneMovement.Step.sum": {
            "value": 999876.0,
            "min": 49969.0,
            "max": 999876.0,
            "count": 20
        },
        "PlaneMovement.Policy.ExtrinsicValueEstimate.mean": {
            "value": 5.826599597930908,
            "min": 2.649371385574341,
            "max": 10.095731735229492,
            "count": 20
        },
        "PlaneMovement.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1171.146484375,
            "min": 561.666748046875,
            "max": 2069.625,
            "count": 20
        },
        "PlaneMovement.Losses.PolicyLoss.mean": {
            "value": 0.09502421210662731,
            "min": 0.09423891755399,
            "max": 0.1020438043722152,
            "count": 20
        },
        "PlaneMovement.Losses.PolicyLoss.sum": {
            "value": 2.090532666345801,
            "min": 2.0781714797167137,
            "max": 2.293431027481453,
            "count": 20
        },
        "PlaneMovement.Losses.ValueLoss.mean": {
            "value": 11.15859731199804,
            "min": 0.22907314152506855,
            "max": 34.26700901852649,
            "count": 20
        },
        "PlaneMovement.Losses.ValueLoss.sum": {
            "value": 245.4891408639569,
            "min": 5.268682255076577,
            "max": 788.1412074261092,
            "count": 20
        },
        "PlaneMovement.Policy.LearningRate.mean": {
            "value": 7.437724793518181e-06,
            "min": 7.437724793518181e-06,
            "max": 0.00029207546173242273,
            "count": 20
        },
        "PlaneMovement.Policy.LearningRate.sum": {
            "value": 0.0001636299454574,
            "min": 0.0001636299454574,
            "max": 0.0064256601581133,
            "count": 20
        },
        "PlaneMovement.Policy.Epsilon.mean": {
            "value": 0.10247920909090907,
            "min": 0.10247920909090907,
            "max": 0.19735848636363637,
            "count": 20
        },
        "PlaneMovement.Policy.Epsilon.sum": {
            "value": 2.2545425999999997,
            "min": 2.2545425999999997,
            "max": 4.4258582,
            "count": 20
        },
        "PlaneMovement.Policy.Beta.mean": {
            "value": 0.00013371253363636366,
            "min": 0.00013371253363636366,
            "max": 0.0048681884695454545,
            "count": 20
        },
        "PlaneMovement.Policy.Beta.sum": {
            "value": 0.002941675740000001,
            "min": 0.002941675740000001,
            "max": 0.10710014633,
            "count": 20
        },
        "PlaneMovement.Environment.EpisodeLength.mean": {
            "value": 981.204081632653,
            "min": 575.5833333333334,
            "max": 981.204081632653,
            "count": 20
        },
        "PlaneMovement.Environment.EpisodeLength.sum": {
            "value": 48079.0,
            "min": 48079.0,
            "max": 51791.0,
            "count": 20
        },
        "PlaneMovement.Environment.CumulativeReward.mean": {
            "value": 571.9566468219368,
            "min": 249.91214421533402,
            "max": 891.4835265537478,
            "count": 20
        },
        "PlaneMovement.Environment.CumulativeReward.sum": {
            "value": 28025.875694274902,
            "min": 15367.044570446014,
            "max": 49084.844467163086,
            "count": 20
        },
        "PlaneMovement.Policy.ExtrinsicReward.mean": {
            "value": 571.9566468219368,
            "min": 249.91214421533402,
            "max": 891.4835265537478,
            "count": 20
        },
        "PlaneMovement.Policy.ExtrinsicReward.sum": {
            "value": 28025.875694274902,
            "min": 15367.044570446014,
            "max": 49084.844467163086,
            "count": 20
        },
        "PlaneMovement.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "PlaneMovement.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1701872558",
        "python_version": "3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Me\\anaconda3\\envs\\unity\\Scripts\\mlagents-learn --run-id=Run7 --force --torch-device=cpu ./run7.yaml",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.19.5",
        "end_time_seconds": "1701874604"
    },
    "total": 2045.3014343,
    "count": 1,
    "self": 0.019973099999788246,
    "children": {
        "run_training.setup": {
            "total": 0.16646529999999998,
            "count": 1,
            "self": 0.16646529999999998
        },
        "TrainerController.start_learning": {
            "total": 2045.1149959000002,
            "count": 1,
            "self": 3.859368900024492,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.753331300000001,
                    "count": 1,
                    "self": 9.753331300000001
                },
                "TrainerController.advance": {
                    "total": 2031.4056343999757,
                    "count": 166863,
                    "self": 4.296455499960075,
                    "children": {
                        "env_step": {
                            "total": 1017.2673281000416,
                            "count": 166863,
                            "self": 644.4916568000457,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 370.2858075999911,
                                    "count": 166863,
                                    "self": 10.89848870004198,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 359.3873188999491,
                                            "count": 166863,
                                            "self": 55.745305799976165,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 303.6420130999729,
                                                    "count": 166863,
                                                    "self": 303.6420130999729
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.4898637000048254,
                                    "count": 166863,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 2030.2406748999995,
                                            "count": 166863,
                                            "is_parallel": true,
                                            "self": 1616.9352719999868,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00042050000000000003,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00019170000000000002,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002288,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002288
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 413.30498240001276,
                                                    "count": 166863,
                                                    "is_parallel": true,
                                                    "self": 16.008458100042333,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 19.428852400008996,
                                                            "count": 166863,
                                                            "is_parallel": true,
                                                            "self": 19.428852400008996
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 325.64210789998145,
                                                            "count": 166863,
                                                            "is_parallel": true,
                                                            "self": 325.64210789998145
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 52.225563999979926,
                                                            "count": 166863,
                                                            "is_parallel": true,
                                                            "self": 28.421764499996236,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 23.80379949998369,
                                                                    "count": 333726,
                                                                    "is_parallel": true,
                                                                    "self": 23.80379949998369
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1009.8418507999739,
                            "count": 166863,
                            "self": 6.351216699954421,
                            "children": {
                                "process_trajectory": {
                                    "total": 56.328837400020674,
                                    "count": 166863,
                                    "self": 56.12688920002073,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.20194819999994706,
                                            "count": 2,
                                            "self": 0.20194819999994706
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 947.1617966999988,
                                    "count": 452,
                                    "self": 186.65004949999116,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 760.5117472000077,
                                            "count": 46200,
                                            "self": 760.5117472000077
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.999999525054591e-07,
                    "count": 1,
                    "self": 7.999999525054591e-07
                },
                "TrainerController._save_models": {
                    "total": 0.09666050000009818,
                    "count": 1,
                    "self": 0.0066768000001502514,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08998369999994793,
                            "count": 1,
                            "self": 0.08998369999994793
                        }
                    }
                }
            }
        }
    }
}